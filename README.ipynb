{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06903c48",
   "metadata": {},
   "source": [
    "## Web APIs & NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ea4c3",
   "metadata": {},
   "source": [
    "By: Zamzam Alsarayrah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b169c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0adc0740",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "As a data scientist for the advertising department at reddit, Our team has recently noticed, during the covid 19 period, an increase in the number of views for special subreddit on the diet and healthy food, and one of the most popular types of diet is Keto. Therefore the team decided to use a classification model to classify the post in two subreddits based on the post title and the post content. This classification will help us to determine in which post to add the specific advertisement.\n",
    "We have two hypothesis to test:\n",
    "The null hypothesis: There is no relation between the post title/post content and the subreddit\n",
    "The alternative hypothesis: there is a relationship between the post title/content and the subreddit and we can predict the subreddit from the post title and post content.\n",
    "To reject or accept the null hypothesis, we have to check the model accuracy, if it is higher than the baseline accuracy we reject the null otherwise accept it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e182ee",
   "metadata": {},
   "source": [
    "**Reddit** is a social news, content, and discussions website. Posts are organised according to subject into user-created 'subreddits'. Members submit content (such as images, texts, and links) to subreddits, which can then be voted up ('upvote') or down ('downvote') by other members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab92f37",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "**- Nutrition** https://www.reddit.com/r/nutrition/\n",
    "\n",
    "**- Keto** https://www.reddit.com/r/keto/\n",
    "\n",
    "Get 5000 different post from nutrition subreddit and 5000 different posts from keto subreddit,50 posts each round, 100 rounds.\n",
    "and I set before to the data of the oldest posts to make sure that each time we get 50 different posts from the last time, wait for 2 seconds before fetching another 50 posts.\n",
    "we only need the post id, titile, selftext and subreddit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec8df8",
   "metadata": {},
   "source": [
    "### Data Cleaning and EDA\n",
    "\n",
    "1- Remove the null value.\n",
    "\n",
    "2- add the length and word counts for both the post content and the post title.\n",
    "\n",
    "3- Replace any (Http , www) with word link.\n",
    "\n",
    "4- Breaking the raw text into small chunks.\n",
    "\n",
    "5- Extract the most common words.\n",
    "\n",
    "6- Add stope words.\n",
    "\n",
    "7- Drop the empty row.\n",
    "\n",
    "8- check the longest and shortest posts (title, self text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72321f74",
   "metadata": {},
   "source": [
    "### Preprocessing and Modeling\n",
    "\n",
    "The Baseline accuracy is 0.5009, our model should have accuracy more than 0.5009 to say it is better than the null model.\n",
    "We are going to pre_proccess the text data before entiring it to the predection model. For this step we are going to use some methods from the Natural Language Processing such as the following methods:\n",
    "\n",
    "- Convert the letter to lowercase letters\n",
    "- Remove special characters\n",
    "- Tokenizing (Split the text into words)\n",
    "- Stemming (get back the base form of the word)\n",
    "- Stop word removal (remove the most occure words in the text)\n",
    "\n",
    "To make it easier to us, we are going to define coustmize token_stemmer class that does the first 4 points of the pre_processing and use this class when using the vectorizer. Also, we are going to make a coustomize stop_words list that contains the \"english\" stop_word is addition to the most common words we found the EDA section.\n",
    "\n",
    "**Modeling**\n",
    "For the modling we are going to use logistic regression, Multinomial Naive Bayes (as we are dealing with possitive integers data) and Random Forests. Also, we are going to alternate between the two vectorizer ( counterVictorizer and the (TF-IDF) Vectorizer). For the predictor, we have two options:\n",
    "\n",
    "use the post content (selftext) alone\n",
    "use the post title alone We have 12 different combinations of the classifiers, vectorizers and the predictors. In this step we are going to define each model, use pipline and RandomizedSearchCV( instead of GridSearchCV to cut down on time spent on hyperparameter tuning)to find the best paramters for the model, fit the train data. The model score and the confusion matrix will be considered in the models scores and comparisons step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51796076",
   "metadata": {},
   "source": [
    "### Conclusion and Recommendations\n",
    "\n",
    "We can notice from the accuracy results for all the models we have examined that the post title, and the post content can be used to classify the post subreddit. The accuracy values for all the 12 models is higher than the Baseline accuracy which was 0.5009. This was the concluded result for all the proposed models. Regarding the best model to use among the tested models, the logistic regression with the Counterectorizer with using the post title as predictor gives as the best scores as we can see from the scores figures and dataframe. It predicted 0.88 of the trained post correctly and 0.8 of the test posts. Also, the recall score were 0.797554 which outperform the other models. The Precision and Specificity scores fot thc chosen model were both good comparing to the other models. If we want to choose other model, we can think about the logistic regression with the TfidfVectorizer using the post title as predictor. This model has scores near to our chosen model. In addition to all the mentioned point regarding the choice of the model that uses Logistic regression, Logistic regression is a very fast classification model comparing to the other model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d62f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
